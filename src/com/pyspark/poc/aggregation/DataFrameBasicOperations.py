'''
Created on 09-Jun-2020

Basic operation on DataFrames

@author: kasho
'''

from com.pyspark.poc.utils.BaseConfUtils import BaseConfUtils

conf = BaseConfUtils()
sparkSess = conf.createSparkSession("DataFrameBasicsOperations")

df = sparkSess.read.csv("D:/Study_Document/GIT/OneStopPySpark/resources/appl_stock.csv",inferSchema=True,header=True)
df.show()

################################################################################################
# Filtering Data: DataFrames has ability to quickly filter out data based on conditions.
# Spark DataFrames are built on top of the Spark SQL platform, which means that is you already know SQL,
# you can quickly and easily grab that data using SQL commands, or using the DataFram methods.
################################################################################################
df.filter("Close<500").show(5)
'''
+-------------------+----------+----------+------------------+------------------+---------+------------------+
|               Date|      Open|      High|               Low|             Close|   Volume|         Adj Close|
+-------------------+----------+----------+------------------+------------------+---------+------------------+
|2010-01-04 00:00:00|213.429998|214.499996|212.38000099999996|        214.009998|123432400|         27.727039|
|2010-01-05 00:00:00|214.599998|215.589994|        213.249994|        214.379993|150476200|27.774976000000002|
|2010-01-06 00:00:00|214.379993|    215.23|        210.750004|        210.969995|138040000|27.333178000000004|
|2010-01-07 00:00:00|    211.75|212.000006|        209.050005|            210.58|119282800|          27.28265|
|2010-01-08 00:00:00|210.299994|212.000006|209.06000500000002|211.98000499999998|111902700|         27.464034|
+-------------------+----------+----------+------------------+------------------+---------+------------------+
'''

df.filter("Close<500").select('Open').show(5)
'''
+----------+
|      Open|
+----------+
|213.429998|
|214.599998|
|214.379993|
|    211.75|
|210.299994|
+----------+
'''

##################################################################################################
#Using normal python comparison operators is another way to do this,
# they will look very similar to SQL operators, except you need to make sure you are calling
# the entire column within the dataframe, using the format: df["column name"]
##################################################################################################
df.filter( (df["Close"] < 200) & (df['Open'] > 200) ).show()

'''
+-------------------+------------------+----------+----------+----------+---------+------------------+
|               Date|              Open|      High|       Low|     Close|   Volume|         Adj Close|
+-------------------+------------------+----------+----------+----------+---------+------------------+
|2010-01-22 00:00:00|206.78000600000001|207.499996|    197.16|    197.75|220441900|         25.620401|
|2010-01-28 00:00:00|        204.930004|205.500004|198.699995|199.289995|293375600|25.819922000000002|
|2010-01-29 00:00:00|        201.079996|202.199995|190.250002|192.060003|311488100|         24.883208|
+-------------------+------------------+----------+----------+----------+---------+------------------+
'''

df.filter( (df["Close"] < 200) | (df['Open'] > 200) ).show(5)
'''
+-------------------+----------+----------+------------------+------------------+---------+------------------+
|               Date|      Open|      High|               Low|             Close|   Volume|         Adj Close|
+-------------------+----------+----------+------------------+------------------+---------+------------------+
|2010-01-04 00:00:00|213.429998|214.499996|212.38000099999996|        214.009998|123432400|         27.727039|
|2010-01-05 00:00:00|214.599998|215.589994|        213.249994|        214.379993|150476200|27.774976000000002|
|2010-01-06 00:00:00|214.379993|    215.23|        210.750004|        210.969995|138040000|27.333178000000004|
|2010-01-07 00:00:00|    211.75|212.000006|        209.050005|            210.58|119282800|          27.28265|
|2010-01-08 00:00:00|210.299994|212.000006|209.06000500000002|211.98000499999998|111902700|         27.464034|
+-------------------+----------+----------+------------------+------------------+---------+------------------+
'''

df.filter( (df["Close"] < 200) & ~(df['Open'] < 200) ).show()
'''
+-------------------+------------------+----------+----------+----------+---------+------------------+
|               Date|              Open|      High|       Low|     Close|   Volume|         Adj Close|
+-------------------+------------------+----------+----------+----------+---------+------------------+
|2010-01-22 00:00:00|206.78000600000001|207.499996|    197.16|    197.75|220441900|         25.620401|
|2010-01-28 00:00:00|        204.930004|205.500004|198.699995|199.289995|293375600|25.819922000000002|
|2010-01-29 00:00:00|        201.079996|202.199995|190.250002|192.060003|311488100|         24.883208|
+-------------------+------------------+----------+----------+----------+---------+------------------+
'''

# Collecting results as Python objects
print(df.filter(df["Low"] == 197.16).collect())
'''
[Row(Date=datetime.datetime(2010, 1, 22, 0, 0), Open=206.78000600000001, 
    High=207.499996, Low=197.16, Close=197.75, Volume=220441900, Adj Close=25.620401)]
'''
result = df.filter(df["Low"] == 197.16).collect()
row = result[0]
#Rows can be called to turn into dictionaries
print(row.asDict())
'''
{'Date': datetime.datetime(2010, 1, 22, 0, 0), 
    'Open': 206.78000600000001, 'High': 207.499996, 
    'Low': 197.16, 'Close': 197.75, 'Volume': 220441900, 
    'Adj Close': 25.620401}
'''

for item in result[0]:
    print(item)
'''
    2010-01-22 00:00:00
    206.78000600000001
    207.499996
    197.16
    197.75
    220441900
    25.620401
'''